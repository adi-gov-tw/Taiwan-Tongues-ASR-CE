<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ASR å³æ™‚è¾¨è­˜æ¸¬è©¦é é¢</title>
  <style>
    body { font-family: Arial, sans-serif; max-width: 1000px; margin: 0 auto; padding: 20px; background-color: #f5f5f5; }
    .container { background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); margin-bottom: 20px; }
    h1 { color: #333; text-align: center; }
    .realtime-container { border: 2px solid #007bff; border-radius: 8px; padding: 15px; margin: 10px 0; }
    .status-indicator { display: inline-block; width: 12px; height: 12px; border-radius: 50%; margin-right: 8px; }
    .status-connected { background-color: #28a745; }
    .status-disconnected { background-color: #dc3545; }
    .controls { text-align: center; margin: 15px 0; }
    .mic-button { font-size: 18px; padding: 15px 30px; border-radius: 50px; transition: all 0.3s ease; background-color: #007bff; color: #fff; border: 0; }
    .mic-button.recording { background-color: #dc3545; animation: pulse 1.5s infinite; }
    @keyframes pulse { 0% { transform: scale(1);} 50% { transform: scale(1.05);} 100% { transform: scale(1);} }
    .transcription-area { background-color: #f8f9fa; border: 1px solid #dee2e6; border-radius: 4px; padding: 15px; margin: 10px 0; min-height: 100px; max-height: 300px; overflow-y: auto; font-family: monospace; font-size: 14px; }
    .transcription-item { margin-bottom: 10px; padding: 8px; background-color: white; border-radius: 4px; border-left: 4px solid #007bff; }
    .transcription-time { font-size: 12px; color: #666; margin-bottom: 5px; }
    .inline-controls { display: flex; gap: 8px; align-items: center; flex-wrap: wrap; justify-content: center; }
    .device-select { min-width: 260px; padding: 6px 8px; }
    .vu-container { width: 240px; height: 10px; background: #eee; border-radius: 5px; overflow: hidden; border: 1px solid #ddd; }
    .vu-bar { height: 100%; width: 0%; background: linear-gradient(90deg, #4caf50, #fbc02d, #e53935); transition: width 80ms linear; }
    .speaking-dot { width: 12px; height: 12px; border-radius: 50%; background: #bbb; display: inline-block; margin-left: 6px; }
    .speaking-dot.active { background: #28a745; }
  </style>
</head>
<body>
  <h1>ASR å³æ™‚è¾¨è­˜æ¸¬è©¦é é¢</h1>

  <div class="container realtime-container">
    <h2>å³æ™‚èªéŸ³è¾¨è­˜ <span id="connectionStatus" class="status-indicator status-disconnected"></span></h2>
    <p>ç‹€æ…‹ï¼š<span id="statusText">æœªé€£æ¥</span></p>

    <div class="controls">
      <div class="inline-controls">
        <select id="audioInputSelect" class="device-select"></select>
        <button onclick="refreshDevices()">åˆ·æ–°è£ç½®</button>
        <div class="vu-container"><div id="vuBar" class="vu-bar"></div></div>
        <span>Speaking</span><span id="speakingDot" class="speaking-dot"></span>
      </div>
      <div style="margin-top:10px; text-align:center;">
        <button id="micButton" class="mic-button" onclick="toggleRecording()" disabled>ğŸ¤ é–‹å§‹éŒ„éŸ³</button>
      </div>
    </div>

    <div class="transcription-area" id="transcriptionArea">
      <p style="text-align: center; color: #666;">ç­‰å¾…èªéŸ³è¼¸å…¥...</p>
    </div>

    <div id="realtimeResult" class="result" style="display: none;"></div>
  </div>

  <script>
    const WS_HOST = (location.hostname || '127.0.0.1');
    const WS_PORT = (location.port && location.port !== '' ? location.port : '5000');
    const WS_PROTO = (location.protocol === 'https:') ? 'wss' : 'ws';
    const WS_BASE = `${WS_PROTO}://${WS_HOST}:${WS_PORT}/ws/v1/transcript`;

    let websocket = null;
    let isRecording = false;
    let isConnected = false;
    let selectedDeviceId = null;
    let speaking = false;
    let speakingFrames = 0;
    let silenceFrames = 0;
    let audioContext = null;
    let processor = null;
    const bufferSize = 4096;
    const targetSampleRate = 16000;
    const targetChunkSize = 2000; // bytes
    // éŸ³é‡ä¼°è¨ˆï¼ˆdB æ¨™å°ºï¼‰èˆ‡å™ªè²é–€æª»
    const EPS = 1e-9;
    let emaRms = 0.0;                  // RMS å¹³æ»‘ï¼ˆç·šæ€§åŸŸï¼‰
    const emaAlpha = 0.2;              // å¹³æ»‘ä¿‚æ•¸
    let emaRmsDb = -120;               // dB å¹³æ»‘
    const emaAlphaDb = 0.3;            // dB å¹³æ»‘ä¿‚æ•¸
    let noiseFloorDb = -120;           // å‹•æ…‹ä¼°è¨ˆçš„é›œè¨Šåº•å™ªï¼ˆdBï¼‰
    let calibrating = true;            // å•Ÿå‹•åˆæœŸå…ˆæ ¡æº–åº•å™ª
    let calibFrames = 0;
    const calibTargetFrames = 50;      // ç”¨å‰ 50 å¹€ä¼°è¨ˆåº•å™ª
    const minDb = -60;                 // VU æ¨™å°ºä¸‹é™ï¼ˆå¯è¦–éœ€è¦èª¿æ•´ï¼‰

    function updateConnectionStatus(status, text) {
      const statusIndicator = document.getElementById('connectionStatus');
      const statusText = document.getElementById('statusText');
      statusIndicator.className = `status-indicator status-${status}`;
      statusText.textContent = text;
    }

    function addTranscription(text, timestamp, isFinal = false) {
      const area = document.getElementById('transcriptionArea');
      if (area.children.length === 1 && area.children[0].tagName === 'P') area.innerHTML = '';
      const item = document.createElement('div');
      item.className = 'transcription-item';
      const time = new Date(timestamp).toLocaleTimeString();
      const timeDiv = document.createElement('div');
      timeDiv.className = 'transcription-time';
      timeDiv.textContent = `${time} ${isFinal ? '(æœ€çµ‚)' : '(å³æ™‚)'}`;
      const textDiv = document.createElement('div');
      textDiv.className = 'transcription-text';
      textDiv.textContent = text;
      item.appendChild(timeDiv); item.appendChild(textDiv); area.appendChild(item);
      area.scrollTop = area.scrollHeight;
    }

    function connectWebSocket() {
      if (websocket) websocket.close();
      const token = 'test_token';
      const userWs = `${WS_BASE}?token=${token}`;
      console.log('é€£æ¥ WebSocket:', userWs);
      websocket = new WebSocket(userWs);
      websocket.onopen = () => { console.log('WebSocket å·²é€£æ¥'); isConnected = true; updateConnectionStatus('connected', 'å·²é€£æ¥'); document.getElementById('micButton').disabled = false; };
      websocket.onclose = (event) => { console.log('WebSocket å·²æ–·é–‹', event); isConnected = false; updateConnectionStatus('disconnected', 'å·²æ–·é–‹'); document.getElementById('micButton').disabled = true; if (isRecording) stopRecording(); };
      websocket.onmessage = (event) => {
        try {
          const data = JSON.parse(event.data);
          // æ–°æ ¼å¼ï¼š{ id, code, message, result: [ { segment, transcript, final, startTime, endTime } ] }
          if (Array.isArray(data.result) && data.result.length > 0) {
            const r = data.result[0];
            addTranscription(r.transcript || '', new Date().toISOString(), !!r.final);
          }
        } catch (e) {
          console.error('è§£æè½‰éŒ„çµæœå¤±æ•—:', e);
        }
      };
      websocket.onerror = (error) => { console.error('WebSocket éŒ¯èª¤:', error); };
    }

    async function initDevices() {
      try { await navigator.mediaDevices.getUserMedia({ audio: true }); } catch (e) { console.warn('éº¥å…‹é¢¨æ¬Šé™å°šæœªå…è¨±'); }
      await refreshDevices();
    }
    async function refreshDevices() {
      try { const devices = await navigator.mediaDevices.enumerateDevices(); const audioInputs = devices.filter(d => d.kind === 'audioinput'); populateDeviceList(audioInputs); } catch (e) { console.error('åˆ—å‡ºè£ç½®å¤±æ•—:', e); }
    }
    function populateDeviceList(audioInputs) {
      const select = document.getElementById('audioInputSelect');
      select.innerHTML = '';
      if (!audioInputs || audioInputs.length === 0) { const opt = document.createElement('option'); opt.value = ''; opt.textContent = 'æœªæ‰¾åˆ°éº¥å…‹é¢¨è£ç½®'; select.appendChild(opt); selectedDeviceId = null; return; }
      audioInputs.forEach((d, idx) => { const opt = document.createElement('option'); opt.value = d.deviceId; opt.textContent = d.label || `éº¥å…‹é¢¨ ${idx+1}`; select.appendChild(opt); });
      if (!selectedDeviceId) selectedDeviceId = audioInputs[0].deviceId;
      select.value = selectedDeviceId;
      select.onchange = () => { if (isRecording) { alert('è«‹å…ˆåœæ­¢éŒ„éŸ³å†åˆ‡æ›è£ç½®'); select.value = selectedDeviceId; return; } selectedDeviceId = select.value || null; };
    }

    function lin2db(x) { return 20 * Math.log10(Math.max(EPS, x)); }
    function db2lin(db) { return Math.pow(10, db / 20); }
    function updateVU(dbVal) {
      // å°‡ dB æ˜ å°„åˆ° 0..1ï¼ˆminDb åˆ° 0 dB ç¯„åœï¼‰
      const level = Math.max(0, Math.min(1, (dbVal - minDb) / (0 - minDb)));
      const bar = document.getElementById('vuBar');
      if (bar) bar.style.width = (level * 100).toFixed(1) + '%';
    }
    function updateSpeaking(dbVal) {
      // å‹•æ…‹åº•å™ªé–€æª»ï¼ˆdBï¼‰ï¼šon/off ä»¥åº•å™ªç‚ºåŸºæº–çš„ä¸Šå‡é‡
      const onFrames = 3, offFrames = 8;
      const speakingOnDb = Math.min(-10, noiseFloorDb + 10); // åº•å™ª +10 dBï¼Œä¸”ä¸è¶…é -10 dB
      const speakingOffDb = Math.min(speakingOnDb - 3, noiseFloorDb + 6); // å›æ»¯ç´„ 3~4 dB

      if (dbVal >= speakingOnDb) {
        speakingFrames += 1;
        silenceFrames = 0;
      } else if (dbVal <= speakingOffDb) {
        silenceFrames += 1;
        speakingFrames = 0;
      } else {
        // è½åœ¨å›æ»¯ä¸­ï¼Œé¿å…ç´¯ç©é€ æˆèª¤åˆ¤
        speakingFrames = 0;
        silenceFrames = 0;
      }

      if (!speaking && speakingFrames >= onFrames) speaking = true;
      if (speaking && silenceFrames >= offFrames) speaking = false;

      const dot = document.getElementById('speakingDot');
      if (dot) { if (speaking) dot.classList.add('active'); else dot.classList.remove('active'); }
    }

    const AUDIO_WORKLET_MODULE_CODE = `
if (typeof AudioWorkletProcessor === 'undefined') {}
class AudioProcessor extends AudioWorkletProcessor {
  constructor(options) { super(); this.bufferSize = options.processorOptions.bufferSize; this.sampleRate = options.processorOptions.sampleRate; this.buffer = new Float32Array(this.bufferSize); this.bufferIndex = 0; }
  process(inputs, outputs, parameters) {
    const input = inputs[0]; const channel = input[0];
    if (channel && channel.length > 0) {
      for (let i = 0; i < channel.length; i++) {
        this.buffer[this.bufferIndex++] = channel[i];
        if (this.bufferIndex === this.bufferSize) { const copy = new Float32Array(this.buffer); this.port.postMessage({ eventType: 'audio', audioBuffer: copy }, [copy.buffer]); this.bufferIndex = 0; }
      }
    }
    return true;
  }
}
registerProcessor('audio-processor', AudioProcessor);
`;
    let audioWorkletModuleUrl = null;
    function getAudioWorkletModuleUrl() { if (!audioWorkletModuleUrl) { const blob = new Blob([AUDIO_WORKLET_MODULE_CODE], { type: 'application/javascript' }); audioWorkletModuleUrl = URL.createObjectURL(blob); } return audioWorkletModuleUrl; }

    function downsampleBuffer(buffer, inputSampleRate, outputSampleRate) {
      if (inputSampleRate === outputSampleRate) return buffer; const ratio = inputSampleRate / outputSampleRate; const newLength = Math.round(buffer.length / ratio); const result = new Float32Array(newLength); let offsetResult = 0, offsetBuffer = 0; while (offsetResult < result.length) { const nextOffsetBuffer = Math.round((offsetResult + 1) * ratio); let accum = 0, count = 0; for (let i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i++) { accum += buffer[i]; count++; } result[offsetResult] = accum / Math.max(count, 1); offsetResult++; offsetBuffer = nextOffsetBuffer; } return result;
    }
    function convertFloat32ToInt16(buffer) { let l = buffer.length; const out = new Int16Array(l); while (l--) { let sample = buffer[l]; sample = Math.max(-1, Math.min(1, sample)); sample = sample * 10.0; sample = Math.max(-1, Math.min(1, sample)); out[l] = Math.round(sample * 0x7FFF); } return out.buffer; }

    let audioBuffer = []; let accumulatedSamples = 0; const targetSamplesPerChunk = targetChunkSize / 2;
    function processAudioFromWorklet(float32Buffer) {
      if (!isRecording || !websocket) return;
      const inputSampleRate = audioContext.sampleRate; const outputSampleRate = targetSampleRate; const downsampledBuffer = downsampleBuffer(float32Buffer, inputSampleRate, outputSampleRate);
      let sumSq = 0; for (let i = 0; i < downsampledBuffer.length; i++) { const v = downsampledBuffer[i]; sumSq += v * v; }
      const rms = Math.sqrt(sumSq / Math.max(1, downsampledBuffer.length));
      // ç·šæ€§åŸŸèˆ‡ dB çš†åšå¹³æ»‘ï¼Œé¡¯ç¤ºæ›´ç©©å®š
      emaRms = emaAlpha * rms + (1 - emaAlpha) * emaRms;
      const rmsDb = lin2db(rms);
      emaRmsDb = emaAlphaDb * rmsDb + (1 - emaAlphaDb) * emaRmsDb;

      // å‰è‹¥å¹²å¹€è‡ªå‹•æ ¡æº–åº•å™ªï¼ˆå– dB å¹³æ»‘å€¼ä¼°è¨ˆï¼‰
      if (calibrating) {
        noiseFloorDb = (noiseFloorDb * calibFrames + emaRmsDb) / Math.max(1, (calibFrames + 1));
        calibFrames += 1;
        if (calibFrames >= calibTargetFrames) calibrating = false;
      } else {
        // åº•å™ªä»¥ç·©æ…¢é€Ÿç‡è·Ÿéš¨ï¼Œé¿å…ç’°å¢ƒé£„ç§»
        noiseFloorDb = 0.98 * noiseFloorDb + 0.02 * emaRmsDb;
      }

      updateVU(emaRmsDb);
      updateSpeaking(emaRmsDb);
      for (let i = 0; i < downsampledBuffer.length; i++) { audioBuffer.push(downsampledBuffer[i]); accumulatedSamples++; if (accumulatedSamples >= targetSamplesPerChunk) { const chunkSamples = audioBuffer.splice(0, targetSamplesPerChunk); accumulatedSamples -= targetSamplesPerChunk; const audioData = convertFloat32ToInt16(chunkSamples); if (websocket && websocket.readyState === WebSocket.OPEN) websocket.send(audioData); } }
    }

    async function startRecording() {
      if (isRecording) return;
      try {
        const AudioContextCtor = window.AudioContext || window.webkitAudioContext; audioContext = new AudioContextCtor();
        const constraints = { audio: { echoCancellation: false, noiseSuppression: false, autoGainControl: false } };
        if (selectedDeviceId) constraints.audio.deviceId = { exact: selectedDeviceId };
        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        const input = audioContext.createMediaStreamSource(stream);
        const canUseWorklet = !!(audioContext.audioWorklet) && window.isSecureContext;
        if (canUseWorklet) {
          try { await audioContext.audioWorklet.addModule(getAudioWorkletModuleUrl()); processor = new AudioWorkletNode(audioContext, 'audio-processor', { outputChannelCount: [1], processorOptions: { bufferSize: bufferSize, sampleRate: audioContext.sampleRate } }); processor.port.onmessage = (event) => { if (event.data && event.data.eventType === 'audio' && event.data.audioBuffer) { const f32 = new Float32Array(event.data.audioBuffer); processAudioFromWorklet(f32); } }; input.connect(processor); processor.connect(audioContext.destination); }
          catch (err) { console.warn('AudioWorklet æ¨¡çµ„è¼‰å…¥å¤±æ•—ï¼Œæ”¹ç”¨ ScriptProcessor å¾Œå‚™æ–¹æ¡ˆ:', err); setupScriptProcessor(input); }
        } else { setupScriptProcessor(input); if (!window.isSecureContext) console.warn('å»ºè­°ä»¥ http://localhost æä¾›é é¢ï¼Œä»¥å•Ÿç”¨ AudioWorklet èˆ‡éº¥å…‹é¢¨æ¬Šé™'); }
        isRecording = true; const micButton = document.getElementById('micButton'); micButton.textContent = 'ğŸ›‘ åœæ­¢éŒ„éŸ³'; micButton.className = 'mic-button recording';
      } catch (error) { console.error('å•Ÿå‹•éŒ„éŸ³å¤±æ•—:', error); alert('ç„¡æ³•å•Ÿå‹•éº¥å…‹é¢¨: ' + (error && error.message ? error.message : String(error))); }
    }
    function setupScriptProcessor(input) { processor = audioContext.createScriptProcessor(bufferSize, 1, 1); processor.onaudioprocess = (e) => { const left = e.inputBuffer.getChannelData(0); processAudioFromWorklet(left); }; input.connect(processor); processor.connect(audioContext.destination); console.log('å·²ä½¿ç”¨ ScriptProcessor å¾Œå‚™æ–¹æ¡ˆ'); }
    function stopRecording() { if (!isRecording) return; isRecording = false; if (processor) { try { processor.disconnect(); } catch (e) {} processor = null; } if (audioContext) { audioContext.close().then(() => audioContext = null); } const micButton = document.getElementById('micButton'); micButton.textContent = 'ğŸ¤ é–‹å§‹éŒ„éŸ³'; micButton.className = 'mic-button'; console.log('éŒ„éŸ³å·²åœæ­¢'); }
    function toggleRecording() { if (!isConnected) { alert('è«‹å…ˆé€£æ¥ WebSocket æœå‹™'); return; } if (isRecording) stopRecording(); else startRecording(); }

    window.onload = function() { connectWebSocket(); initDevices(); };
    window.onbeforeunload = function() { if (isRecording) stopRecording(); if (websocket) websocket.close(); };
  </script>
</body>
</html>


